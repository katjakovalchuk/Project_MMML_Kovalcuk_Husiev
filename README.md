# Final Project MMML
Authors (team):
- Kovalchuk Kateryna: https://github.com/katjakovalchuk
- Husiev Radomyr: https://github.com/rhusiev

## Introduction
Neural networks are a very useful and complicated tool that is now used to solve complex problems quite quickly. However, the more complicated the task, the more complex the model needed for it, and the more complex the model, the longer it takes to train and the more memory it uses to run. 

To solve this problem, different approaches are used, some of which we will review and implement during this project. 
One of these methods is Model Pruning, which reduces the number of parameters by squeezing out those weights that are considered unnecessary. However, this can lead to bad results, so this method should be approached very carefully. The LoRA approach and SVD are also used for this task to reduce the size of Weight Matrix for faster model work. 

These methods are discussed in more detail in the [Report](https://www.overleaf.com/read/gcxxkntmythn#be4477)
